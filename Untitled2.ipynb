{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Z9mMrAkF8r-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "1649f53c-3133-40cc-e422-420863772146"
      },
      "cell_type": "code",
      "source": [
        "#1 Слой свертки, 75 карт признаков, размер ядра свертки: 5х5.\n",
        "#2 Слой подвыборки, размер пула 2х2.\n",
        "#3 Слой свертки, 100 карт признаков, размер ядра свертки 5х5.\n",
        "#4 Слой подвыборки, размер пула 2х2.\n",
        "#5 Полносвязный слой, 500 нейронов.\n",
        "#6 Полносвязный выходной слой, 10 нейронов, которые соответствуют классам рукописных цифр от 0 до 9.\n",
        "\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Устанавливаем seed для повторяемости результатов\n",
        "numpy.random.seed(42)\n",
        "\n",
        "# Размер изображения\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# Загружаем данные\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Преобразование размерности изображений\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Нормализация данных\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Преобразуем метки в категории\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Создаем последовательную модель\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(75, kernel_size=(5, 5),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(100, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Обучаем сеть\n",
        "model.fit(X_train, Y_train, batch_size=200, epochs=10, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Оцениваем качество обучения сети на тестовых данных\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "#СОХРАНЕНИЕ МОДЕЛИ\n",
        "#АРХИТЕКТУРА\n",
        "\n",
        "#Генерируем описание модели в формате json\n",
        "model_json = model.to_json()\n",
        "\n",
        "#Записываем модель в файл\n",
        "json_file = open(\"convmnist_model.json\", \"w\")\n",
        "json_file.write(model_json)\n",
        "json_file.close()\n",
        "\n",
        "#ВЕСА\n",
        "model.save_weights('convmnist_model.h5')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 75)        1950      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 75)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 75)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 100)         187600    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               800500    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 995,060\n",
            "Trainable params: 995,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            " - 12s - loss: 0.2630 - acc: 0.9164 - val_loss: 0.0598 - val_acc: 0.9821\n",
            "Epoch 2/10\n",
            " - 6s - loss: 0.0673 - acc: 0.9797 - val_loss: 0.0426 - val_acc: 0.9871\n",
            "Epoch 3/10\n",
            " - 6s - loss: 0.0453 - acc: 0.9868 - val_loss: 0.0344 - val_acc: 0.9892\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.0376 - acc: 0.9879 - val_loss: 0.0302 - val_acc: 0.9903\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.0312 - acc: 0.9904 - val_loss: 0.0269 - val_acc: 0.9915\n",
            "Epoch 6/10\n",
            " - 6s - loss: 0.0265 - acc: 0.9914 - val_loss: 0.0297 - val_acc: 0.9915\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.0235 - acc: 0.9924 - val_loss: 0.0275 - val_acc: 0.9924\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0272 - val_acc: 0.9930\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0284 - val_acc: 0.9925\n",
            "Epoch 10/10\n",
            " - 6s - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0278 - val_acc: 0.9916\n",
            "Точность работы на тестовых данных: 99.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTHuVPnjB7hL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1320
        },
        "outputId": "a1393582-220f-4928-ab33-017e92ace354"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Устанавливаем seed для повторяемости результатов\n",
        "numpy.random.seed(42)\n",
        "\n",
        "# Размер изображения\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# Загружаем данные\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Преобразование размерности изображений\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Нормализация данных\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Преобразуем метки в категории\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Создаем последовательную модель\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(75, kernel_size=(5, 5),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(100, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Обучаем сеть\n",
        "model.fit(X_train, Y_train, batch_size=200, epochs=10, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Оцениваем качество обучения сети на тестовых данных\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# Загружаем изображение\n",
        "img_path = '2.png'\n",
        "img = image.load_img(img_path, target_size=(28, 28))\n",
        "color_mode = \"grayscale\"\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Преобразуем изображением в массив numpy\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Инвертируем и нормализуем изображение\n",
        "x = 255 - x\n",
        "x /= 255\n",
        "#Добавление еще одного измерения в картинку\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#Предсказание цифры\n",
        "prediction = model.predict(X)\n",
        "prediction = np_utils.categorical_probas_to_classes(prediction)\n",
        "print(prediction)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 75)        1950      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 75)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 12, 12, 75)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 100)         187600    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 500)               800500    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 995,060\n",
            "Trainable params: 995,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2631 - acc: 0.9162 - val_loss: 0.0605 - val_acc: 0.9812\n",
            "Epoch 2/10\n",
            " - 6s - loss: 0.0669 - acc: 0.9796 - val_loss: 0.0427 - val_acc: 0.9871\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.0450 - acc: 0.9864 - val_loss: 0.0343 - val_acc: 0.9888\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.0374 - acc: 0.9880 - val_loss: 0.0306 - val_acc: 0.9905\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.0309 - acc: 0.9905 - val_loss: 0.0266 - val_acc: 0.9918\n",
            "Epoch 6/10\n",
            " - 6s - loss: 0.0271 - acc: 0.9909 - val_loss: 0.0273 - val_acc: 0.9915\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.0239 - acc: 0.9921 - val_loss: 0.0278 - val_acc: 0.9921\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.0190 - acc: 0.9935 - val_loss: 0.0284 - val_acc: 0.9923\n",
            "Epoch 9/10\n",
            " - 6s - loss: 0.0188 - acc: 0.9934 - val_loss: 0.0275 - val_acc: 0.9923\n",
            "Epoch 10/10\n",
            " - 6s - loss: 0.0162 - acc: 0.9943 - val_loss: 0.0255 - val_acc: 0.9931\n",
            "Точность работы на тестовых данных: 99.32%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-74e79e723872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Загружаем изображение\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, target_size, interpolation)\u001b[0m\n\u001b[1;32m    385\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    386\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2.png'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "S8IQ8jVzDY2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "6e2debe2-0eb4-40fe-b364-59e793811757"
      },
      "cell_type": "code",
      "source": [
        "img_path = '2.png'\n",
        "img = image.load_img(img_path, target_size=(28, 28))\n",
        "color_mode = \"grayscale\"\n",
        "plt.imshow(img, cmap='gray')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7cc56c302851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_hayVBHTFSva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LwQf96ZiEob_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XKQ9ABaE5kJ",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "b8c245e6-b068-4dd8-d52e-bbfe39a5210e"
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b6ad9bf1-c7a3-4a3b-bc1e-1f515abfc602\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b6ad9bf1-c7a3-4a3b-bc1e-1f515abfc602\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 2.png to 2.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2.png': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x06\\x00\\x00\\x00r\\r\\xdf\\x94\\x00\\x00\\x01\\x98IDATx\\x9c\\xed\\x96=\\x8e\\xc20\\x10\\x85\\x1f\\xcb\\x16\\xd0G4P\\xe0\\x86*\\x12\\x05\\x12\\xadG\\x1c\\x86\\xd2>\\x829\\x02\\\\\\x83+\\x00\\x92\\x1b\\x8a !\\x11\\x89\\n)\\xa6\\xe1\\x00t\\x94\\xb3U\\x90\\xd8\\xdd$\\xce\\xcfR\\xed+\\xed\\xb1\\xbf\\xccx\\xfc\\x9c\\x1633\\xde\\xa8\\x8fw\\xc2\\x00\\xe0\\xb3\\xea\\xc2\\xc5b\\xe15\\xf6]\\xa53t\\xce\\x81\\x88`\\xad}\\x19\\xb7\\xd6\\x82\\x88\\xe0\\x9c\\xcb\\xdf\\x80=\\x94$\\t\\x1bcXk\\xcdA\\x10\\xb0\\xd6\\xfa\\xd7\\xb8t\\xde9\\x97\\xb9W!p\\xbb\\xdd>!\\xc6\\x18N\\x92$7^)\\xc5J\\xa9j@k-\\x07A\\xc0\\xbb\\xdd\\xae\\xe8\\xbb\\x9er\\xce\\xe5f\\x99\\tL\\x17Zk\\xbda\\xa9\\x94Rl\\x8c\\xf9u.\\xb3i\\x84\\x10\\x88\\xa2\\x08R\\xca\\xb2}\\x858\\x8e\\xeb5M\\xd9\\xec\\xa4\\x94\\x99\\xf3\\x8d\\x02\\x8b\\xce\\x8f\\x99\\xb9\\xc5\\xdc\\x9c\\xb5i\\xad\\x01\\x00\\xab\\xd5\\xea\\xefK\\xeas\\x07\\x99\\x99+[\\x1b\\x00\\xec\\xf7{l6\\x9b\\xa7\\xebDQ\\x04!D\\xee\\x9aJ%=\\x9dN\\x98\\xcf\\xe7\\x00\\x80\\xd9l\\x86N\\xa7\\xe3\\xe5\\xa3\\x00\\xca\\x974u\\x9e\\xf5z]\\xa9\\xf4\\xa5\\x80i\\x17\\x96q\\x9eZ@)e\\xaeO\\xfa\\xc8\\xfb\\x0c\\x89\\x08\\x00~<Ke\\xe5\\xf5\\x1e\\xa6\\xf7\\xcb\\x07V\\xd4<\\x85\\x19^\\xafWL\\xa7S\\x1c\\x0e\\x07\\x08!\\xf0x<\\x10\\xc71\\xce\\xe73n\\xb7\\xdbK\\xecr\\xb9\\x04\\x00\\xdc\\xef\\xf7\\xea\\xc0\\xe1p\\x88^\\xaf\\x870\\x0cq<\\x1eq\\xb9\\\\0\\x1a\\x8d0\\x99L\\xd0\\xef\\xf7\\xd1n\\xb7_\\xe2kgHD \"\\x0c\\x06\\x03\\x84a\\x88\\xf1x\\x8cn\\xb7\\x9b\\xbbi-`\\xd3z\\xfbo\\xe2?\\xb0q}\\x01\\x00\\xf4\\x8c\\x96\\xf4\\xdd\\x1b\\xa4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "BS68VXRTFUgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "63089c62-d9d3-4b24-cd77-912371b9b22d"
      },
      "cell_type": "code",
      "source": [
        " img_path = '2.png'\n",
        "---->img = image.load_img(img_path, target_size=(28, 28))\n",
        "      3 color_mode = \"grayscale\"\n",
        "      4 plt.imshow(img, cmap='gray')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-f916133ae011>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ----> 2 img = image.load_img(img_path, target_size=(28, 28))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "iH2YYBWfFaTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "b2480bfc-fad6-45fb-9e05-f91190ef30e6"
      },
      "cell_type": "code",
      "source": [
        " img_path = '2.png'\n",
        " img = image.load_img(img_path, target_size=(28, 28))\n",
        " color_mode = \"grayscale\"\n",
        " plt.imshow(img, cmap='gray')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7cc56c302851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "peuw_QC7F-1f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Устанавливаем seed для повторяемости результатов\n",
        "numpy.random.seed(42)\n",
        "\n",
        "# Размер изображения\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# Загружаем данные\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Преобразование размерности изображений\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Нормализация данных\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Преобразуем метки в категории\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Создаем последовательную модель\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(75, kernel_size=(5, 5),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(100, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Обучаем сеть\n",
        "model.fit(X_train, Y_train, batch_size=200, epochs=10, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Оцениваем качество обучения сети на тестовых данных\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# Загружаем изображение\n",
        "img_path = '2.png'\n",
        "img = image.load_img(img_path, target_size=(28, 28))\n",
        "color_mode = \"grayscale\"\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Преобразуем изображением в массив numpy\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Инвертируем и нормализуем изображение\n",
        "x = 255 - x\n",
        "x /= 255\n",
        "#Добавление еще одного измерения в картинку\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#Предсказание цифры\n",
        "prediction = model.predict(X)\n",
        "prediction = np_utils.categorical_probas_to_classes(prediction)\n",
        "print(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rO2nJNBIGjAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uPyloNTyGboY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NaRJQ4IGGk3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "26967391-d64f-4958-875a-7a7506ea974d"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "\n",
        "# Устанавливаем seed для повторяемости результатов\n",
        "numpy.random.seed(42)\n",
        "\n",
        "# Размер изображения\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# Загружаем данные\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Преобразование размерности изображений\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Нормализация данных\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Преобразуем метки в категории\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Создаем последовательную модель\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(75, kernel_size=(5, 5),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(100, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Обучаем сеть\n",
        "model.fit(X_train, Y_train, batch_size=200, epochs=10, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Оцениваем качество обучения сети на тестовых данных\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 75)        1950      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 12, 12, 75)        0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 12, 12, 75)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 100)         187600    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 500)               800500    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 995,060\n",
            "Trainable params: 995,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2629 - acc: 0.9162 - val_loss: 0.0606 - val_acc: 0.9817\n",
            "Epoch 2/10\n",
            " - 6s - loss: 0.0672 - acc: 0.9792 - val_loss: 0.0410 - val_acc: 0.9877\n",
            "Epoch 3/10\n",
            " - 6s - loss: 0.0456 - acc: 0.9863 - val_loss: 0.0364 - val_acc: 0.9888\n",
            "Epoch 4/10\n",
            " - 6s - loss: 0.0372 - acc: 0.9881 - val_loss: 0.0313 - val_acc: 0.9902\n",
            "Epoch 5/10\n",
            " - 6s - loss: 0.0307 - acc: 0.9903 - val_loss: 0.0279 - val_acc: 0.9918\n",
            "Epoch 6/10\n",
            " - 6s - loss: 0.0269 - acc: 0.9915 - val_loss: 0.0283 - val_acc: 0.9919\n",
            "Epoch 7/10\n",
            " - 6s - loss: 0.0227 - acc: 0.9926 - val_loss: 0.0273 - val_acc: 0.9928\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.0181 - acc: 0.9941 - val_loss: 0.0270 - val_acc: 0.9928\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.0178 - acc: 0.9940 - val_loss: 0.0299 - val_acc: 0.9917\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.0161 - acc: 0.9941 - val_loss: 0.0280 - val_acc: 0.9918\n",
            "Точность работы на тестовых данных: 99.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4OBcW9PyGvPa",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "17a66de6-46a1-4f3f-c650-82a8b3f4ac56"
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-53f8c926-71cc-43d2-97cb-9d50aa3e8a7b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-53f8c926-71cc-43d2-97cb-9d50aa3e8a7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-63b259460c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "G-lGBEuqVZa9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cc9c490-ef02-432b-aa74-3dc570c238cc"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image as im\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "\n",
        "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "\n",
        "    return gray\n",
        "\n",
        "  \n",
        "img_path = '2.png'\n",
        "img = im.load_img(img_path, target_size=(28, 28))\n",
        "x = image.img_to_array(img)\n",
        "g = rgb2gray(x)\n",
        "\n",
        "b=gray.shape\n",
        "print(b)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JP79dGTzG8Ze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "00a6a146-b10d-46e9-bb01-a4bd21b28a09"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Загружаем изображение\n",
        "# img_path = '3.bmp'\n",
        "# img = image.load_img(img_path, target_size=(28, 28))\n",
        "# color_mode = \"grayscale\"\n",
        "# plt.imshow(img, cmap='gray')\n",
        "# plt.show()\n",
        "\n",
        "# Преобразуем изображением в массив numpy\n",
        "# x = image.img_to_array(img)\n",
        "\n",
        "# Инвертируем и нормализуем изображение\n",
        "g = 255-g\n",
        "g /= 255\n",
        "#Добавление еще одного измерения в картинку\n",
        "g = np.expand_dims(g, axis=3)\n",
        "g = np.expand_dims(g, axis=0)\n",
        "\n",
        "c=g.shape\n",
        "print(c)\n",
        "\n",
        "#Предсказание цифры\n",
        "prediction = model.predict(g)\n",
        "prediction = np.argmax(prediction)\n",
        "print(prediction)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28, 1)\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "w9apt13YmFQB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "b = np.array([[0, 1, 2, 3], [10, 11, 12, 13], [20, 21, 22, 23], [30, 31, 32, 33], [40, 41, 42, 43]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZK_7TCHQmLxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e275d39-32f2-429d-9988-9eba6b382077"
      },
      "cell_type": "code",
      "source": [
        "b[1, 0]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "pcrboN5amnBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f76874d8-da4d-4531-bfd1-fb2ca86110c4"
      },
      "cell_type": "code",
      "source": [
        "print(b.shape)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NQNYhx_Nnehc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "outputId": "0468756e-29d4-4008-cb65-7b2aa33a82c6"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загружаем данные об архитектуре сети из файла json\n",
        "print('Загружаю сеть из файлов')\n",
        "json_file = open(\"convmnist_model.json\", \"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "# Создаем модель на основе загруженных данных\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# Загружаем веса в модель\n",
        "loaded_model.load_weights(\"convmnist_model.h5\")\n",
        "print('Загрузка сети завершена')\n",
        "\n",
        "\n",
        "# Компилируем загруженную модель\n",
        "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Загружаем изображение\n",
        "img_path = '2.png'\n",
        "img = image.load_img(img_path, target_size=(28, 28))\n",
        "color_mode = \"grayscale\"\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Преобразуем изображением в массив numpy\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Инвертируем и нормализуем изображение\n",
        "x = 255 - x\n",
        "x /= 255\n",
        "#Добавление еще одного измерения в картинку\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#Предсказание цифры\n",
        "prediction = loaded_model.predict(x)\n",
        "prediction = np_utils.categorical_probas_to_classes(prediction)\n",
        "print(prediction)\n",
        "#Модель выдает массив из 10 значений в формате One Hot Encoding.\n",
        "#Выбираем индекс максимального значения и печатаем его:"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Загружаю сеть из файлов\n",
            "Загрузка сети завершена\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff9adbd8630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-5eab4bd74830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#Предсказание цифры\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_probas_to_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1064\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking : expected conv2d_1_input to have shape (28, 28, 1) but got array with shape (28, 28, 3)"
          ]
        }
      ]
    }
  ]
}